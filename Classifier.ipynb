{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn import linear_model as lm\n",
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_vec = pd.read_csv('select_word.csv', sep=',',header=None).values\n",
    "word_vec = word_vec[1:,0]\n",
    "hashtag_vec = pd.read_csv('select_hashtag.csv', sep=',',header=None).values\n",
    "hashtag_vec = hashtag_vec[1:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "# Build Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#data_path = 'hashtag_vec.mat'\n",
    "\n",
    "def compute_logistic(data_path):\n",
    "    data = sio.loadmat(data_path)\n",
    "    print(\"data keys\", data.keys())\n",
    "    org_account_type = data['training_labels'].T\n",
    "    org_account_data = data['training_data']\n",
    "    org_account_order = data['known_account_order']\n",
    "    indiv_account_data = data['individual_data'] \n",
    "    indiv_account_order = data['individual_account_order'] \n",
    "\n",
    "    # Normalize the data set\n",
    "    normed_org_acnt_data = normalize(org_account_data, axis=1, norm='l2')\n",
    "    normed_indiv_data = normalize(indiv_account_data, axis=1, norm='l2')\n",
    "\n",
    "    # Fit the model to logistic function\n",
    "    logistic = lm.LogisticRegression(fit_intercept=True)\n",
    "    logistic.fit(normed_org_acnt_data, org_account_type)\n",
    "    print('LogisticRegression score: %f'\n",
    "          % logistic.fit(normed_org_acnt_data, org_account_type).score(normed_org_acnt_data, org_account_type))\n",
    "\n",
    "    # Calculate the strength of the belief for accounts\n",
    "    org_strengths = logistic.predict_proba(normed_org_acnt_data)\n",
    "    indiv_strengths = logistic.predict_proba(normed_indiv_data)\n",
    "\n",
    "    indiv_pred = logistic.predict(normed_indiv_data)\n",
    "    org_pred = logistic.predict(normed_org_acnt_data)\n",
    "    \n",
    "    file_dict = {}\n",
    "    file_dict['individual_account_order'] = indiv_account_order\n",
    "    file_dict['org_account_order'] = org_account_order\n",
    "    file_dict['indiv_prochoice_strength'] = indiv_strengths[:,0]\n",
    "    file_dict['indiv_prolife_strength'] = indiv_strengths[:,1]\n",
    "    file_dict['org_prochoice_strength'] = org_strengths[:,0]\n",
    "    file_dict['org_prolife_strength'] = org_strengths[:,1]\n",
    "    file_dict['indiv_class'] = indiv_pred\n",
    "    file_dict['org_class'] = org_pred\n",
    "    if 'hashtag' in data_path:\n",
    "        mat_path = 'logistic_prop_{}.mat'.format('hashtag')\n",
    "        indiv_combine_path = \"indiv_strength_diversity_{}.csv\".format('hashtag')\n",
    "        org_combine_path = \"org_strength_diversity_{}.csv\".format('hashtag')\n",
    "    else:\n",
    "        mat_path = 'logistic_prop_{}.mat'.format('word')\n",
    "        indiv_combine_path = \"indiv_strength_diversity_{}.csv\".format('word')\n",
    "        org_combine_path = \"org_strength_diversity_{}.csv\".format('word')\n",
    "        \n",
    "    sio.savemat(mat_path, file_dict, do_compression=True) \n",
    "    combine_diversity_logistic(indiv_account_order, indiv_strengths[:,0], indiv_strengths[:,1], indiv_pred, \n",
    "                               indiv_combine_path)\n",
    "    combine_diversity_logistic(org_account_order, org_strengths[:,0], org_strengths[:,1], org_pred, \n",
    "                               org_combine_path)\n",
    "    return logistic.coef_\n",
    "\n",
    "def combine_diversity_logistic(account_order, prochoice_strength, prolife_strength, pred_class, save_path):\n",
    "    classifier_df = pd.DataFrame({\n",
    "                        \"account_name\": [s.strip() for s in account_order], \n",
    "                        \"prochoice_strength\": prochoice_strength,\n",
    "                        \"prolife_strength\": prolife_strength,\n",
    "                        \"predict_class\": pred_class\n",
    "                        })\n",
    "    if \"indiv\" in save_path:\n",
    "        prolife_followers = []\n",
    "        with open('./prolife_followers.csv', 'r') as f:\n",
    "            reader = csv.reader(f)\n",
    "            for item in list(reader):\n",
    "                prolife_followers += item\n",
    "        assert len(set(prolife_followers))==100\n",
    "\n",
    "        prochoice_followers = []\n",
    "        with open('./prochoice_followers.csv', 'r') as f:\n",
    "            reader = csv.reader(f)\n",
    "            for item in list(reader):\n",
    "                prochoice_followers += item\n",
    "        assert len(set(prochoice_followers))==100\n",
    "\n",
    "        classifier_df['follower of'] = [0 if user in prolife_followers and user in prochoice_followers \n",
    "                            else 1 if user in prolife_followers else -1 for user in classifier_df['account_name']]\n",
    "        following_proportion = pd.read_csv('proportion.csv')\n",
    "        combine_df = pd.merge(classifier_df, following_proportion, left_on='account_name', right_on='User', how='left')\n",
    "        result_df = combine_df.drop_duplicates()\n",
    "        result_df = result_df.drop('User', axis=1)\n",
    "    else:\n",
    "        prolife_proportion = pd.read_csv('prolife_proportion.csv')\n",
    "        prochoice_proportion = pd.read_csv('prochoice_proportion.csv')\n",
    "        result_df = pd.concat([prolife_proportion, prochoice_proportion])\n",
    "        result_df = pd.merge(classifier_df, result_df, left_on='account_name', right_on='User', how='left')\n",
    "        result_df = result_df.drop('User', axis=1)\n",
    "        result_df['account_type'] = [1]*40+[0]*40\n",
    "    result_df.to_csv(save_path, index=False)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data keys dict_keys(['__header__', 'individual_data', '__globals__', '__version__', 'training_data', 'known_account_order', 'training_labels', 'individual_account_order'])\n",
      "LogisticRegression score: 0.987500\n",
      "data keys dict_keys(['__header__', 'individual_data', '__globals__', '__version__', 'training_data', 'known_account_order', 'training_labels', 'individual_account_order'])\n",
      "LogisticRegression score: 0.987500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/juntan/anaconda3/envs/datascience/lib/python3.5/site-packages/sklearn/utils/validation.py:526: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "word_logistic_coef = compute_logistic(\"word_vec.mat\")\n",
    "hashtag_logistic_coef = compute_logistic(\"hashtag_vec.mat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we fit the logistic model to the hand labeled popular accounts, we can use the logistic model to predict the type of the individual accounts and the strength of the belief. $logistic.predict$ produces the probability of the sample for each class in the model, where classes are ordered as they are in logistic.classes_ = array([0, 1]), 1 is prolife, 0 is prochoice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['prolife ', 'repealthe8th ', 'prochoice ', 'beboldendhyde ',\n",
       "       'stopthesham ', 'defundpp ', 'protestpp ', 'reprojustice ',\n",
       "       'shoutyourabortion ', 'reprorights ', 'ppsellsbabyparts ',\n",
       "       'periscope ', 'plannedparenthood ', 'icommittoprayread ',\n",
       "       'givingtuesday ', '9daysforlife ', 'womensmarch ',\n",
       "       'prolifewomen16 ', 'demsinphilly ', '40daysforlife '], dtype=object)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pick out words with the largest coefficient in absolute value.\n",
    "coef=abs(hashtag_logistic_coef.flatten())\n",
    "sig = np.argsort(-coef)\n",
    "sig = sig.flatten()\n",
    "ind = sig[0:20]\n",
    "coef[ind]\n",
    "hashtag_vec[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
